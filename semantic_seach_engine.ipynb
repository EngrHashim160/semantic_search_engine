{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a semantic search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will build a search engine over a PDF document. This will allow us to retrieve passages in the PDF that are similar to an input query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (0.3.16)\n",
      "Collecting pypdf\n",
      "  Downloading pypdf-5.3.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (3.11.11)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.16 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (0.3.17)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (0.3.35)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (0.3.5)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain<0.4.0,>=0.3.16->langchain-community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.32->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.16->langchain-community) (2.27.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\hashimedisk\\endtoendprojects\\langchain\\langchain_env\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading pypdf-5.3.0-py3-none-any.whl (300 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError('A certificate chain processed, but terminated in a root certificate which is not trusted by the trust provider.'))': /simple/pypdf/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError('A certificate chain processed, but terminated in a root certificate which is not trusted by the trust provider.'))': /simple/pypdf/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError('A certificate chain processed, but terminated in a root certificate which is not trusted by the trust provider.'))': /simple/pypdf/\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"./gen_ai.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\HashimEdisk\\EndToEndProjects\\LangChain\\langchain_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\PMLS\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated vectors of length 384\n",
      "\n",
      "[-0.3988904654979706, 0.21661382913589478, -0.38683268427848816, 0.10741971433162689, 0.039315272122621536, 0.02057838812470436, -0.32118719816207886, 0.1605253517627716, 0.1680615097284317, -0.13747482001781464]\n"
     ]
    }
   ],
   "source": [
    "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
    "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
    "\n",
    "assert len(vector_1) == len(vector_2)\n",
    "print(f\"Generated vectors of length {len(vector_1)}\\n\")\n",
    "print(vector_1[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_store = Chroma(embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='and businesses should seek to understand and embrace the \n",
      "potential of generative AI (Eloundou et al., 2023; Willcocks, \n",
      "2020).\n",
      "Challenges for generative AI‑based systems\n",
      "While generative AI holds transformative potential for \n",
      "individuals, organizations, and society due to its vast pos-\n",
      "sible application space, the technology also inherits vari-\n",
      "ous challenges that parallel those of traditional ML and \n",
      "DL systems. The domain of electronic markets is a prime \n",
      "example that moved into the center of transformation \n",
      "due to its latest focus on data-driven efforts (Selz, 2020). \n",
      "Outlining and emphasizing these challenges relevant for \n",
      "research and practice helps to raise awareness of the con-\n",
      "straints as well as supports future efforts in developing, \n",
      "implementing, and improving GAI-based systems.\n",
      "Bias\n",
      "Because of GAI’s data-driven nature, data quality plays an \n",
      "essential role in how GAI-based systems perform and, thus, \n",
      "how feasible their adoption for real-world scenarios in busi-' metadata={'page': 7, 'page_label': '8', 'source': './gen_ai.pdf', 'start_index': 789}\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"What are the Challenges for generative AI‑based systems?\"\n",
    ")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Electronic Markets           (2023) 33:63 \n",
      "1 3   63  Page 2 of 17\n",
      "While GAI research and development is continuing to \n",
      "invest toward better, faster, and more capable models (e.g., \n",
      "Microsoft, 2023), studies on the fundamental principles, \n",
      "applications, and socio-economic impact remain largely \n",
      "unexplored in the academic discourse (Strobel et al., 2024; \n",
      "Susarla et al., 2023; Wessel et al., 2023). GAI provides inno-\n",
      "vation opportunities for various domains (e.g., networked \n",
      "businesses and digital platforms) but also comes with chal-\n",
      "lenges (e.g., transparency, biases, and misuse) that need to \n",
      "be addressed for successful implementations (Houde et al., \n",
      "2020; Schramowski et al., 2022; van Slyke et al., 2023). \n",
      "However, an examination of the key concepts is yet to be \n",
      "conducted, leaving a clear image and understanding of gen-\n",
      "erative AI undefined. To overcome that shortcoming, this \n",
      "article provides an introduction to the fundamentals of gen-' metadata={'page': 2, 'page_label': '3', 'source': './gen_ai.pdf', 'start_index': 1}\n"
     ]
    }
   ],
   "source": [
    "results = await vector_store.asimilarity_search(\"When was Nike incorporated?\")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 58.756858825683594\n",
      "\n",
      "page_content='Electronic Markets           (2023) 33:63 \n",
      "1 3   63  Page 2 of 17\n",
      "While GAI research and development is continuing to \n",
      "invest toward better, faster, and more capable models (e.g., \n",
      "Microsoft, 2023), studies on the fundamental principles, \n",
      "applications, and socio-economic impact remain largely \n",
      "unexplored in the academic discourse (Strobel et al., 2024; \n",
      "Susarla et al., 2023; Wessel et al., 2023). GAI provides inno-\n",
      "vation opportunities for various domains (e.g., networked \n",
      "businesses and digital platforms) but also comes with chal-\n",
      "lenges (e.g., transparency, biases, and misuse) that need to \n",
      "be addressed for successful implementations (Houde et al., \n",
      "2020; Schramowski et al., 2022; van Slyke et al., 2023). \n",
      "However, an examination of the key concepts is yet to be \n",
      "conducted, leaving a clear image and understanding of gen-\n",
      "erative AI undefined. To overcome that shortcoming, this \n",
      "article provides an introduction to the fundamentals of gen-' metadata={'page': 2, 'page_label': '3', 'source': './gen_ai.pdf', 'start_index': 1}\n"
     ]
    }
   ],
   "source": [
    "# Note that providers implement different scores; the score here\n",
    "# is a distance metric that varies inversely with similarity.\n",
    "\n",
    "results = vector_store.similarity_search_with_score(\"What was Nike's revenue in 2023?\")\n",
    "doc, score = results[0]\n",
    "print(f\"Score: {score}\\n\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return documents based on similarity to an embedded query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='and businesses should seek to understand and embrace the \n",
      "potential of generative AI (Eloundou et al., 2023; Willcocks, \n",
      "2020).\n",
      "Challenges for generative AI‑based systems\n",
      "While generative AI holds transformative potential for \n",
      "individuals, organizations, and society due to its vast pos-\n",
      "sible application space, the technology also inherits vari-\n",
      "ous challenges that parallel those of traditional ML and \n",
      "DL systems. The domain of electronic markets is a prime \n",
      "example that moved into the center of transformation \n",
      "due to its latest focus on data-driven efforts (Selz, 2020). \n",
      "Outlining and emphasizing these challenges relevant for \n",
      "research and practice helps to raise awareness of the con-\n",
      "straints as well as supports future efforts in developing, \n",
      "implementing, and improving GAI-based systems.\n",
      "Bias\n",
      "Because of GAI’s data-driven nature, data quality plays an \n",
      "essential role in how GAI-based systems perform and, thus, \n",
      "how feasible their adoption for real-world scenarios in busi-' metadata={'page': 7, 'page_label': '8', 'source': './gen_ai.pdf', 'start_index': 789}\n"
     ]
    }
   ],
   "source": [
    "embedding = embeddings.embed_query(\"What are the Challenges for generative AI‑based systems?\")\n",
    "\n",
    "results = vector_store.similarity_search_by_vector(embedding)\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
